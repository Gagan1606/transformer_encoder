Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
done w all_ - [0, 0, 0, 0, 0, 0, 4, 4, 4, 4]
batching done
done w all_ - [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
batching done
done w all_ - [0, 6, 0, 0, 0, 0, 0, 0, 0, 0]
batching done
done w all_ - [0, 0, 0, 0, 0, 0, 4, 4, 4, 4]
batching done
done w all_ - [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
batching done
starting training....
batch 0 done - batch_loss: 1.82, batch_acc:10.00
batch 50 done - batch_loss: 0.95, batch_acc:56.67
batch 100 done - batch_loss: 0.62, batch_acc:93.33
batch 150 done - batch_loss: 0.58, batch_acc:83.33
batch 200 done - batch_loss: 0.77, batch_acc:90.00
batch 250 done - batch_loss: 0.64, batch_acc:76.67
batch 300 done - batch_loss: 0.81, batch_acc:73.33
batch 350 done - batch_loss: 0.36, batch_acc:93.33
batch 400 done - batch_loss: 0.55, batch_acc:86.67
batch 450 done - batch_loss: 0.37, batch_acc:96.67
batch 500 done - batch_loss: 0.45, batch_acc:90.00
batch 550 done - batch_loss: 1.11, batch_acc:50.00
batch 600 done - batch_loss: 1.39, batch_acc:66.67
batch 650 done - batch_loss: 0.90, batch_acc:80.00
batch 700 done - batch_loss: 0.81, batch_acc:70.00
batch 750 done - batch_loss: 0.58, batch_acc:73.33
batch 800 done - batch_loss: 0.99, batch_acc:70.00
batch 850 done - batch_loss: 0.87, batch_acc:53.33
batch 900 done - batch_loss: 0.98, batch_acc:66.67
batch 950 done - batch_loss: 0.90, batch_acc:70.00
batch 1000 done - batch_loss: 0.59, batch_acc:90.00
batch 1050 done - batch_loss: 1.42, batch_acc:73.33
batch 1100 done - batch_loss: 0.46, batch_acc:83.33
batch 1150 done - batch_loss: 0.72, batch_acc:53.33
batch 1200 done - batch_loss: 0.20, batch_acc:100.00
batch 1250 done - batch_loss: 0.57, batch_acc:86.67
batch 1300 done - batch_loss: 0.28, batch_acc:93.33
batch 1350 done - batch_loss: 0.52, batch_acc:80.00
batch 1400 done - batch_loss: 0.67, batch_acc:80.00
batch 1450 done - batch_loss: 0.10, batch_acc:100.00
batch 1500 done - batch_loss: 0.39, batch_acc:83.33
batch 1550 done - batch_loss: 0.36, batch_acc:90.00
batch 1600 done - batch_loss: 0.36, batch_acc:90.00
batch 1650 done - batch_loss: 0.16, batch_acc:93.33
batch 1700 done - batch_loss: 1.37, batch_acc:70.00
batch 1750 done - batch_loss: 0.47, batch_acc:86.67
batch 1800 done - batch_loss: 0.26, batch_acc:93.33
batch 1850 done - batch_loss: 0.22, batch_acc:93.33
batch 1900 done - batch_loss: 0.42, batch_acc:86.67
batch 1950 done - batch_loss: 0.29, batch_acc:93.33
batch 2000 done - batch_loss: 0.34, batch_acc:90.00
batch 2050 done - batch_loss: 0.21, batch_acc:93.33
batch 2100 done - batch_loss: 0.45, batch_acc:83.33
batch 2150 done - batch_loss: 0.30, batch_acc:86.67
batch 2200 done - batch_loss: 0.28, batch_acc:93.33
batch 2250 done - batch_loss: 0.37, batch_acc:90.00
batch 2300 done - batch_loss: 0.10, batch_acc:100.00
batch 2350 done - batch_loss: 0.54, batch_acc:80.00
batch 2400 done - batch_loss: 0.41, batch_acc:83.33
batch 2450 done - batch_loss: 0.18, batch_acc:96.67
batch 2500 done - batch_loss: 0.31, batch_acc:90.00
batch 2550 done - batch_loss: 0.19, batch_acc:90.00
batch 2600 done - batch_loss: 1.04, batch_acc:73.33
batch 2650 done - batch_loss: 0.61, batch_acc:80.00
batch 2700 done - batch_loss: 0.39, batch_acc:83.33
batch 2750 done - batch_loss: 0.39, batch_acc:90.00
batch 2800 done - batch_loss: 0.29, batch_acc:90.00
batch 2850 done - batch_loss: 0.17, batch_acc:93.33
batch 2900 done - batch_loss: 0.16, batch_acc:93.33
starting validation....
training - epoch:0, avg_loss:0.55, avg_acc:82.74
val - epoch:0, avg_loss:0.36, avg_acc:88.35
batch 0 done - batch_loss: 0.41, batch_acc:86.67
batch 50 done - batch_loss: 0.85, batch_acc:56.67
batch 100 done - batch_loss: 0.55, batch_acc:83.33
batch 150 done - batch_loss: 0.39, batch_acc:90.00
batch 200 done - batch_loss: 0.79, batch_acc:86.67
batch 250 done - batch_loss: 0.44, batch_acc:80.00
batch 300 done - batch_loss: 0.66, batch_acc:73.33
batch 350 done - batch_loss: 0.21, batch_acc:96.67
batch 400 done - batch_loss: 0.43, batch_acc:86.67
batch 450 done - batch_loss: 0.29, batch_acc:96.67
batch 500 done - batch_loss: 0.43, batch_acc:86.67
batch 550 done - batch_loss: 1.07, batch_acc:50.00
batch 600 done - batch_loss: 1.03, batch_acc:70.00
batch 650 done - batch_loss: 0.92, batch_acc:80.00
batch 700 done - batch_loss: 0.73, batch_acc:73.33
batch 750 done - batch_loss: 0.54, batch_acc:73.33
batch 800 done - batch_loss: 1.02, batch_acc:63.33
batch 850 done - batch_loss: 0.80, batch_acc:70.00
batch 900 done - batch_loss: 0.79, batch_acc:66.67
batch 950 done - batch_loss: 0.90, batch_acc:70.00
batch 1000 done - batch_loss: 0.48, batch_acc:80.00
batch 1050 done - batch_loss: 1.29, batch_acc:73.33
batch 1100 done - batch_loss: 0.43, batch_acc:80.00
batch 1150 done - batch_loss: 0.65, batch_acc:60.00
batch 1200 done - batch_loss: 0.21, batch_acc:100.00
batch 1250 done - batch_loss: 0.50, batch_acc:90.00
batch 1300 done - batch_loss: 0.24, batch_acc:96.67
batch 1350 done - batch_loss: 0.50, batch_acc:76.67
batch 1400 done - batch_loss: 0.66, batch_acc:76.67
batch 1450 done - batch_loss: 0.08, batch_acc:100.00
batch 1500 done - batch_loss: 0.42, batch_acc:80.00
batch 1550 done - batch_loss: 0.23, batch_acc:93.33
batch 1600 done - batch_loss: 0.35, batch_acc:93.33
batch 1650 done - batch_loss: 0.15, batch_acc:100.00
batch 1700 done - batch_loss: 1.33, batch_acc:70.00
batch 1750 done - batch_loss: 0.36, batch_acc:90.00
batch 1800 done - batch_loss: 0.20, batch_acc:93.33
batch 1850 done - batch_loss: 0.16, batch_acc:93.33
batch 1900 done - batch_loss: 0.20, batch_acc:86.67
batch 1950 done - batch_loss: 0.23, batch_acc:93.33
batch 2000 done - batch_loss: 0.23, batch_acc:90.00
batch 2050 done - batch_loss: 0.15, batch_acc:93.33
batch 2100 done - batch_loss: 0.25, batch_acc:93.33
batch 2150 done - batch_loss: 0.21, batch_acc:90.00
batch 2200 done - batch_loss: 0.30, batch_acc:93.33
batch 2250 done - batch_loss: 0.18, batch_acc:96.67
batch 2300 done - batch_loss: 0.06, batch_acc:100.00
batch 2350 done - batch_loss: 0.47, batch_acc:83.33
batch 2400 done - batch_loss: 0.30, batch_acc:90.00
batch 2450 done - batch_loss: 0.17, batch_acc:93.33
batch 2500 done - batch_loss: 0.27, batch_acc:90.00
batch 2550 done - batch_loss: 0.12, batch_acc:90.00
batch 2600 done - batch_loss: 0.88, batch_acc:80.00
batch 2650 done - batch_loss: 0.64, batch_acc:76.67
batch 2700 done - batch_loss: 0.25, batch_acc:93.33
batch 2750 done - batch_loss: 0.34, batch_acc:93.33
batch 2800 done - batch_loss: 0.19, batch_acc:93.33
batch 2850 done - batch_loss: 0.14, batch_acc:96.67
batch 2900 done - batch_loss: 0.13, batch_acc:93.33
starting validation....
training - epoch:1, avg_loss:0.48, avg_acc:83.88
val - epoch:1, avg_loss:0.33, avg_acc:89.07
batch 0 done - batch_loss: 0.34, batch_acc:90.00
batch 50 done - batch_loss: 0.82, batch_acc:60.00
batch 100 done - batch_loss: 0.48, batch_acc:83.33
batch 150 done - batch_loss: 0.37, batch_acc:90.00
batch 200 done - batch_loss: 0.74, batch_acc:83.33
batch 250 done - batch_loss: 0.36, batch_acc:86.67
batch 300 done - batch_loss: 0.65, batch_acc:70.00
batch 350 done - batch_loss: 0.20, batch_acc:96.67
batch 400 done - batch_loss: 0.38, batch_acc:90.00
batch 450 done - batch_loss: 0.29, batch_acc:93.33
batch 500 done - batch_loss: 0.37, batch_acc:93.33
batch 550 done - batch_loss: 0.92, batch_acc:53.33
batch 600 done - batch_loss: 0.98, batch_acc:66.67
batch 650 done - batch_loss: 0.91, batch_acc:80.00
batch 700 done - batch_loss: 0.70, batch_acc:73.33
batch 750 done - batch_loss: 0.52, batch_acc:70.00
batch 800 done - batch_loss: 0.93, batch_acc:60.00
batch 850 done - batch_loss: 0.80, batch_acc:70.00
batch 900 done - batch_loss: 0.75, batch_acc:70.00
batch 950 done - batch_loss: 0.84, batch_acc:66.67
batch 1000 done - batch_loss: 0.41, batch_acc:83.33
batch 1050 done - batch_loss: 1.28, batch_acc:70.00
batch 1100 done - batch_loss: 0.36, batch_acc:86.67
batch 1150 done - batch_loss: 0.64, batch_acc:66.67
batch 1200 done - batch_loss: 0.20, batch_acc:96.67
batch 1250 done - batch_loss: 0.47, batch_acc:90.00
batch 1300 done - batch_loss: 0.20, batch_acc:96.67
batch 1350 done - batch_loss: 0.47, batch_acc:76.67
batch 1400 done - batch_loss: 0.64, batch_acc:83.33
batch 1450 done - batch_loss: 0.11, batch_acc:100.00
batch 1500 done - batch_loss: 0.41, batch_acc:80.00
batch 1550 done - batch_loss: 0.22, batch_acc:86.67
batch 1600 done - batch_loss: 0.38, batch_acc:93.33
batch 1650 done - batch_loss: 0.15, batch_acc:96.67
batch 1700 done - batch_loss: 1.24, batch_acc:70.00
batch 1750 done - batch_loss: 0.31, batch_acc:93.33
batch 1800 done - batch_loss: 0.20, batch_acc:93.33
batch 1850 done - batch_loss: 0.15, batch_acc:93.33
batch 1900 done - batch_loss: 0.18, batch_acc:93.33
batch 1950 done - batch_loss: 0.20, batch_acc:93.33
batch 2000 done - batch_loss: 0.22, batch_acc:90.00
batch 2050 done - batch_loss: 0.13, batch_acc:93.33
batch 2100 done - batch_loss: 0.20, batch_acc:93.33
batch 2150 done - batch_loss: 0.17, batch_acc:90.00
batch 2200 done - batch_loss: 0.31, batch_acc:96.67
batch 2250 done - batch_loss: 0.17, batch_acc:93.33
batch 2300 done - batch_loss: 0.04, batch_acc:100.00
batch 2350 done - batch_loss: 0.43, batch_acc:83.33
batch 2400 done - batch_loss: 0.26, batch_acc:93.33
batch 2450 done - batch_loss: 0.18, batch_acc:90.00
batch 2500 done - batch_loss: 0.25, batch_acc:90.00
batch 2550 done - batch_loss: 0.11, batch_acc:93.33
batch 2600 done - batch_loss: 0.90, batch_acc:80.00
batch 2650 done - batch_loss: 0.62, batch_acc:80.00
batch 2700 done - batch_loss: 0.24, batch_acc:93.33
batch 2750 done - batch_loss: 0.29, batch_acc:93.33
batch 2800 done - batch_loss: 0.17, batch_acc:93.33
batch 2850 done - batch_loss: 0.14, batch_acc:96.67
batch 2900 done - batch_loss: 0.13, batch_acc:93.33
starting validation....
training - epoch:2, avg_loss:0.45, avg_acc:84.69
val - epoch:2, avg_loss:0.32, avg_acc:89.32
batch 0 done - batch_loss: 0.33, batch_acc:90.00
batch 50 done - batch_loss: 0.78, batch_acc:63.33
batch 100 done - batch_loss: 0.45, batch_acc:86.67
batch 150 done - batch_loss: 0.37, batch_acc:90.00
batch 200 done - batch_loss: 0.69, batch_acc:83.33
batch 250 done - batch_loss: 0.32, batch_acc:90.00
batch 300 done - batch_loss: 0.59, batch_acc:70.00
batch 350 done - batch_loss: 0.21, batch_acc:96.67
batch 400 done - batch_loss: 0.35, batch_acc:93.33
batch 450 done - batch_loss: 0.27, batch_acc:93.33
batch 500 done - batch_loss: 0.30, batch_acc:93.33
batch 550 done - batch_loss: 0.83, batch_acc:63.33
batch 600 done - batch_loss: 0.96, batch_acc:70.00
batch 650 done - batch_loss: 0.89, batch_acc:76.67
batch 700 done - batch_loss: 0.68, batch_acc:73.33
batch 750 done - batch_loss: 0.53, batch_acc:70.00
batch 800 done - batch_loss: 0.91, batch_acc:66.67
batch 850 done - batch_loss: 0.78, batch_acc:66.67
batch 900 done - batch_loss: 0.71, batch_acc:66.67
batch 950 done - batch_loss: 0.79, batch_acc:66.67
batch 1000 done - batch_loss: 0.39, batch_acc:86.67
batch 1050 done - batch_loss: 1.23, batch_acc:70.00
batch 1100 done - batch_loss: 0.34, batch_acc:90.00
batch 1150 done - batch_loss: 0.62, batch_acc:66.67
batch 1200 done - batch_loss: 0.20, batch_acc:96.67
batch 1250 done - batch_loss: 0.44, batch_acc:90.00
batch 1300 done - batch_loss: 0.20, batch_acc:96.67
batch 1350 done - batch_loss: 0.44, batch_acc:76.67
batch 1400 done - batch_loss: 0.65, batch_acc:80.00
batch 1450 done - batch_loss: 0.11, batch_acc:100.00
batch 1500 done - batch_loss: 0.40, batch_acc:80.00
batch 1550 done - batch_loss: 0.21, batch_acc:86.67
batch 1600 done - batch_loss: 0.36, batch_acc:93.33
batch 1650 done - batch_loss: 0.14, batch_acc:96.67
batch 1700 done - batch_loss: 1.14, batch_acc:70.00
batch 1750 done - batch_loss: 0.29, batch_acc:93.33
batch 1800 done - batch_loss: 0.19, batch_acc:93.33
batch 1850 done - batch_loss: 0.13, batch_acc:93.33
batch 1900 done - batch_loss: 0.18, batch_acc:93.33
batch 1950 done - batch_loss: 0.19, batch_acc:96.67
batch 2000 done - batch_loss: 0.20, batch_acc:90.00
batch 2050 done - batch_loss: 0.12, batch_acc:93.33
batch 2100 done - batch_loss: 0.19, batch_acc:96.67
batch 2150 done - batch_loss: 0.15, batch_acc:93.33
batch 2200 done - batch_loss: 0.31, batch_acc:96.67
batch 2250 done - batch_loss: 0.17, batch_acc:93.33
batch 2300 done - batch_loss: 0.04, batch_acc:100.00
batch 2350 done - batch_loss: 0.40, batch_acc:83.33
batch 2400 done - batch_loss: 0.24, batch_acc:86.67
batch 2450 done - batch_loss: 0.19, batch_acc:93.33
batch 2500 done - batch_loss: 0.24, batch_acc:90.00
batch 2550 done - batch_loss: 0.11, batch_acc:93.33
batch 2600 done - batch_loss: 0.90, batch_acc:80.00
batch 2650 done - batch_loss: 0.62, batch_acc:80.00
batch 2700 done - batch_loss: 0.25, batch_acc:93.33
batch 2750 done - batch_loss: 0.24, batch_acc:93.33
batch 2800 done - batch_loss: 0.17, batch_acc:93.33
batch 2850 done - batch_loss: 0.13, batch_acc:96.67
batch 2900 done - batch_loss: 0.12, batch_acc:93.33
starting validation....
training - epoch:3, avg_loss:0.43, avg_acc:85.10
val - epoch:3, avg_loss:0.31, avg_acc:89.47
batch 0 done - batch_loss: 0.33, batch_acc:90.00
batch 50 done - batch_loss: 0.75, batch_acc:66.67
batch 100 done - batch_loss: 0.43, batch_acc:90.00
batch 150 done - batch_loss: 0.37, batch_acc:90.00
batch 200 done - batch_loss: 0.66, batch_acc:83.33
batch 250 done - batch_loss: 0.28, batch_acc:93.33
batch 300 done - batch_loss: 0.55, batch_acc:70.00
batch 350 done - batch_loss: 0.21, batch_acc:96.67
batch 400 done - batch_loss: 0.32, batch_acc:93.33
batch 450 done - batch_loss: 0.26, batch_acc:93.33
batch 500 done - batch_loss: 0.29, batch_acc:93.33
batch 550 done - batch_loss: 0.80, batch_acc:66.67
batch 600 done - batch_loss: 0.95, batch_acc:70.00
batch 650 done - batch_loss: 0.86, batch_acc:76.67
batch 700 done - batch_loss: 0.66, batch_acc:73.33
batch 750 done - batch_loss: 0.52, batch_acc:70.00
batch 800 done - batch_loss: 0.89, batch_acc:66.67
batch 850 done - batch_loss: 0.77, batch_acc:66.67
batch 900 done - batch_loss: 0.68, batch_acc:66.67
batch 950 done - batch_loss: 0.72, batch_acc:66.67
batch 1000 done - batch_loss: 0.38, batch_acc:90.00
batch 1050 done - batch_loss: 1.19, batch_acc:73.33
batch 1100 done - batch_loss: 0.31, batch_acc:90.00
batch 1150 done - batch_loss: 0.61, batch_acc:66.67
batch 1200 done - batch_loss: 0.19, batch_acc:96.67
batch 1250 done - batch_loss: 0.41, batch_acc:90.00
batch 1300 done - batch_loss: 0.19, batch_acc:96.67
batch 1350 done - batch_loss: 0.41, batch_acc:83.33
batch 1400 done - batch_loss: 0.66, batch_acc:80.00
batch 1450 done - batch_loss: 0.12, batch_acc:100.00
batch 1500 done - batch_loss: 0.39, batch_acc:80.00
batch 1550 done - batch_loss: 0.18, batch_acc:86.67
batch 1600 done - batch_loss: 0.34, batch_acc:93.33
batch 1650 done - batch_loss: 0.13, batch_acc:96.67
batch 1700 done - batch_loss: 1.06, batch_acc:70.00
batch 1750 done - batch_loss: 0.25, batch_acc:93.33
batch 1800 done - batch_loss: 0.17, batch_acc:93.33
batch 1850 done - batch_loss: 0.11, batch_acc:96.67
batch 1900 done - batch_loss: 0.18, batch_acc:93.33
batch 1950 done - batch_loss: 0.18, batch_acc:96.67
batch 2000 done - batch_loss: 0.19, batch_acc:90.00
batch 2050 done - batch_loss: 0.10, batch_acc:93.33
batch 2100 done - batch_loss: 0.19, batch_acc:96.67
batch 2150 done - batch_loss: 0.14, batch_acc:93.33
batch 2200 done - batch_loss: 0.30, batch_acc:96.67
batch 2250 done - batch_loss: 0.17, batch_acc:93.33
batch 2300 done - batch_loss: 0.04, batch_acc:100.00
batch 2350 done - batch_loss: 0.39, batch_acc:80.00
batch 2400 done - batch_loss: 0.22, batch_acc:90.00
batch 2450 done - batch_loss: 0.18, batch_acc:90.00
batch 2500 done - batch_loss: 0.23, batch_acc:90.00
batch 2550 done - batch_loss: 0.10, batch_acc:93.33
batch 2600 done - batch_loss: 0.88, batch_acc:80.00
batch 2650 done - batch_loss: 0.63, batch_acc:80.00
batch 2700 done - batch_loss: 0.25, batch_acc:90.00
batch 2750 done - batch_loss: 0.22, batch_acc:96.67
batch 2800 done - batch_loss: 0.16, batch_acc:93.33
batch 2850 done - batch_loss: 0.12, batch_acc:96.67
batch 2900 done - batch_loss: 0.11, batch_acc:93.33
starting validation....
training - epoch:4, avg_loss:0.42, avg_acc:85.41
val - epoch:4, avg_loss:0.31, avg_acc:89.48
batch 0 done - batch_loss: 0.32, batch_acc:90.00
batch 50 done - batch_loss: 0.71, batch_acc:73.33
batch 100 done - batch_loss: 0.40, batch_acc:90.00
batch 150 done - batch_loss: 0.38, batch_acc:90.00
batch 200 done - batch_loss: 0.62, batch_acc:83.33
batch 250 done - batch_loss: 0.24, batch_acc:96.67
batch 300 done - batch_loss: 0.51, batch_acc:73.33
batch 350 done - batch_loss: 0.23, batch_acc:96.67
batch 400 done - batch_loss: 0.30, batch_acc:93.33
batch 450 done - batch_loss: 0.25, batch_acc:93.33
batch 500 done - batch_loss: 0.27, batch_acc:93.33
batch 550 done - batch_loss: 0.77, batch_acc:66.67
batch 600 done - batch_loss: 0.93, batch_acc:73.33
batch 650 done - batch_loss: 0.84, batch_acc:76.67
batch 700 done - batch_loss: 0.63, batch_acc:80.00
batch 750 done - batch_loss: 0.51, batch_acc:70.00
batch 800 done - batch_loss: 0.86, batch_acc:63.33
batch 850 done - batch_loss: 0.76, batch_acc:70.00
batch 900 done - batch_loss: 0.67, batch_acc:66.67
batch 950 done - batch_loss: 0.67, batch_acc:66.67
batch 1000 done - batch_loss: 0.36, batch_acc:86.67
batch 1050 done - batch_loss: 1.15, batch_acc:73.33
batch 1100 done - batch_loss: 0.29, batch_acc:90.00
batch 1150 done - batch_loss: 0.59, batch_acc:70.00
batch 1200 done - batch_loss: 0.19, batch_acc:96.67
batch 1250 done - batch_loss: 0.38, batch_acc:90.00
batch 1300 done - batch_loss: 0.19, batch_acc:96.67
batch 1350 done - batch_loss: 0.38, batch_acc:83.33
batch 1400 done - batch_loss: 0.64, batch_acc:80.00
batch 1450 done - batch_loss: 0.12, batch_acc:96.67
batch 1500 done - batch_loss: 0.38, batch_acc:80.00
batch 1550 done - batch_loss: 0.16, batch_acc:93.33
batch 1600 done - batch_loss: 0.32, batch_acc:93.33
batch 1650 done - batch_loss: 0.12, batch_acc:96.67
batch 1700 done - batch_loss: 0.97, batch_acc:70.00
batch 1750 done - batch_loss: 0.21, batch_acc:93.33
batch 1800 done - batch_loss: 0.15, batch_acc:93.33
batch 1850 done - batch_loss: 0.10, batch_acc:100.00
batch 1900 done - batch_loss: 0.18, batch_acc:93.33
batch 1950 done - batch_loss: 0.17, batch_acc:96.67
batch 2000 done - batch_loss: 0.18, batch_acc:93.33
batch 2050 done - batch_loss: 0.08, batch_acc:96.67
batch 2100 done - batch_loss: 0.19, batch_acc:96.67
batch 2150 done - batch_loss: 0.13, batch_acc:93.33
batch 2200 done - batch_loss: 0.29, batch_acc:96.67
batch 2250 done - batch_loss: 0.16, batch_acc:90.00
batch 2300 done - batch_loss: 0.04, batch_acc:100.00
batch 2350 done - batch_loss: 0.36, batch_acc:83.33
batch 2400 done - batch_loss: 0.21, batch_acc:90.00
batch 2450 done - batch_loss: 0.17, batch_acc:93.33
batch 2500 done - batch_loss: 0.23, batch_acc:90.00
batch 2550 done - batch_loss: 0.10, batch_acc:93.33
batch 2600 done - batch_loss: 0.85, batch_acc:80.00
batch 2650 done - batch_loss: 0.64, batch_acc:83.33
batch 2700 done - batch_loss: 0.24, batch_acc:90.00
batch 2750 done - batch_loss: 0.20, batch_acc:96.67
batch 2800 done - batch_loss: 0.14, batch_acc:93.33
batch 2850 done - batch_loss: 0.11, batch_acc:96.67
batch 2900 done - batch_loss: 0.09, batch_acc:93.33
starting validation....
training - epoch:5, avg_loss:0.40, avg_acc:85.81
val - epoch:5, avg_loss:0.32, avg_acc:89.47
batch 0 done - batch_loss: 0.30, batch_acc:90.00
batch 50 done - batch_loss: 0.63, batch_acc:73.33
batch 100 done - batch_loss: 0.37, batch_acc:90.00
batch 150 done - batch_loss: 0.38, batch_acc:90.00
batch 200 done - batch_loss: 0.58, batch_acc:83.33
batch 250 done - batch_loss: 0.22, batch_acc:96.67
batch 300 done - batch_loss: 0.47, batch_acc:80.00
batch 350 done - batch_loss: 0.24, batch_acc:96.67
batch 400 done - batch_loss: 0.28, batch_acc:93.33
batch 450 done - batch_loss: 0.23, batch_acc:93.33
batch 500 done - batch_loss: 0.27, batch_acc:90.00
batch 550 done - batch_loss: 0.73, batch_acc:70.00
batch 600 done - batch_loss: 0.91, batch_acc:73.33
batch 650 done - batch_loss: 0.81, batch_acc:76.67
batch 700 done - batch_loss: 0.59, batch_acc:83.33
batch 750 done - batch_loss: 0.49, batch_acc:70.00
batch 800 done - batch_loss: 0.82, batch_acc:63.33
batch 850 done - batch_loss: 0.75, batch_acc:70.00
batch 900 done - batch_loss: 0.65, batch_acc:73.33
batch 950 done - batch_loss: 0.63, batch_acc:70.00
batch 1000 done - batch_loss: 0.34, batch_acc:86.67
batch 1050 done - batch_loss: 1.09, batch_acc:73.33
batch 1100 done - batch_loss: 0.28, batch_acc:90.00
batch 1150 done - batch_loss: 0.56, batch_acc:76.67
batch 1200 done - batch_loss: 0.19, batch_acc:96.67
batch 1250 done - batch_loss: 0.36, batch_acc:90.00
batch 1300 done - batch_loss: 0.19, batch_acc:96.67
batch 1350 done - batch_loss: 0.34, batch_acc:83.33
batch 1400 done - batch_loss: 0.62, batch_acc:80.00
batch 1450 done - batch_loss: 0.14, batch_acc:93.33
batch 1500 done - batch_loss: 0.36, batch_acc:80.00
batch 1550 done - batch_loss: 0.15, batch_acc:93.33
batch 1600 done - batch_loss: 0.30, batch_acc:90.00
batch 1650 done - batch_loss: 0.11, batch_acc:96.67
batch 1700 done - batch_loss: 0.85, batch_acc:70.00
batch 1750 done - batch_loss: 0.18, batch_acc:93.33
batch 1800 done - batch_loss: 0.13, batch_acc:93.33
batch 1850 done - batch_loss: 0.09, batch_acc:100.00
batch 1900 done - batch_loss: 0.19, batch_acc:90.00
batch 1950 done - batch_loss: 0.16, batch_acc:96.67
batch 2000 done - batch_loss: 0.16, batch_acc:90.00
batch 2050 done - batch_loss: 0.07, batch_acc:96.67
batch 2100 done - batch_loss: 0.18, batch_acc:96.67
batch 2150 done - batch_loss: 0.12, batch_acc:93.33
batch 2200 done - batch_loss: 0.27, batch_acc:96.67
batch 2250 done - batch_loss: 0.16, batch_acc:90.00
batch 2300 done - batch_loss: 0.03, batch_acc:100.00
batch 2350 done - batch_loss: 0.32, batch_acc:90.00
batch 2400 done - batch_loss: 0.21, batch_acc:93.33
batch 2450 done - batch_loss: 0.16, batch_acc:93.33
batch 2500 done - batch_loss: 0.21, batch_acc:90.00
batch 2550 done - batch_loss: 0.10, batch_acc:93.33
batch 2600 done - batch_loss: 0.80, batch_acc:80.00
batch 2650 done - batch_loss: 0.63, batch_acc:83.33
batch 2700 done - batch_loss: 0.24, batch_acc:90.00
batch 2750 done - batch_loss: 0.17, batch_acc:96.67
batch 2800 done - batch_loss: 0.13, batch_acc:93.33
batch 2850 done - batch_loss: 0.09, batch_acc:96.67
batch 2900 done - batch_loss: 0.08, batch_acc:93.33
starting validation....
training - epoch:6, avg_loss:0.38, avg_acc:86.31
val - epoch:6, avg_loss:0.32, avg_acc:89.33
batch 0 done - batch_loss: 0.28, batch_acc:90.00
batch 50 done - batch_loss: 0.55, batch_acc:83.33
batch 100 done - batch_loss: 0.32, batch_acc:90.00
batch 150 done - batch_loss: 0.38, batch_acc:90.00
batch 200 done - batch_loss: 0.53, batch_acc:83.33
batch 250 done - batch_loss: 0.20, batch_acc:96.67
batch 300 done - batch_loss: 0.41, batch_acc:80.00
batch 350 done - batch_loss: 0.24, batch_acc:96.67
batch 400 done - batch_loss: 0.26, batch_acc:93.33
batch 450 done - batch_loss: 0.21, batch_acc:93.33
batch 500 done - batch_loss: 0.29, batch_acc:86.67
batch 550 done - batch_loss: 0.72, batch_acc:70.00
batch 600 done - batch_loss: 0.88, batch_acc:73.33
batch 650 done - batch_loss: 0.79, batch_acc:76.67
batch 700 done - batch_loss: 0.57, batch_acc:83.33
batch 750 done - batch_loss: 0.47, batch_acc:73.33
batch 800 done - batch_loss: 0.77, batch_acc:66.67
batch 850 done - batch_loss: 0.74, batch_acc:66.67
batch 900 done - batch_loss: 0.59, batch_acc:73.33
batch 950 done - batch_loss: 0.58, batch_acc:73.33
batch 1000 done - batch_loss: 0.31, batch_acc:90.00
batch 1050 done - batch_loss: 1.03, batch_acc:76.67
batch 1100 done - batch_loss: 0.26, batch_acc:93.33
batch 1150 done - batch_loss: 0.54, batch_acc:80.00
batch 1200 done - batch_loss: 0.20, batch_acc:96.67
batch 1250 done - batch_loss: 0.34, batch_acc:90.00
batch 1300 done - batch_loss: 0.18, batch_acc:96.67
batch 1350 done - batch_loss: 0.32, batch_acc:86.67
batch 1400 done - batch_loss: 0.58, batch_acc:80.00
batch 1450 done - batch_loss: 0.15, batch_acc:93.33
batch 1500 done - batch_loss: 0.33, batch_acc:80.00
batch 1550 done - batch_loss: 0.13, batch_acc:96.67
batch 1600 done - batch_loss: 0.29, batch_acc:86.67
batch 1650 done - batch_loss: 0.10, batch_acc:100.00
batch 1700 done - batch_loss: 0.76, batch_acc:76.67
batch 1750 done - batch_loss: 0.15, batch_acc:93.33
batch 1800 done - batch_loss: 0.11, batch_acc:93.33
batch 1850 done - batch_loss: 0.08, batch_acc:100.00
batch 1900 done - batch_loss: 0.19, batch_acc:90.00
batch 1950 done - batch_loss: 0.14, batch_acc:96.67
batch 2000 done - batch_loss: 0.15, batch_acc:93.33
batch 2050 done - batch_loss: 0.06, batch_acc:96.67
batch 2100 done - batch_loss: 0.17, batch_acc:96.67
batch 2150 done - batch_loss: 0.11, batch_acc:93.33
batch 2200 done - batch_loss: 0.22, batch_acc:96.67
batch 2250 done - batch_loss: 0.15, batch_acc:90.00
batch 2300 done - batch_loss: 0.03, batch_acc:100.00
batch 2350 done - batch_loss: 0.27, batch_acc:90.00
batch 2400 done - batch_loss: 0.19, batch_acc:90.00
batch 2450 done - batch_loss: 0.16, batch_acc:93.33
batch 2500 done - batch_loss: 0.20, batch_acc:90.00
batch 2550 done - batch_loss: 0.11, batch_acc:93.33
batch 2600 done - batch_loss: 0.72, batch_acc:80.00
batch 2650 done - batch_loss: 0.61, batch_acc:83.33
batch 2700 done - batch_loss: 0.23, batch_acc:86.67
batch 2750 done - batch_loss: 0.14, batch_acc:96.67
batch 2800 done - batch_loss: 0.12, batch_acc:93.33
batch 2850 done - batch_loss: 0.08, batch_acc:96.67
batch 2900 done - batch_loss: 0.08, batch_acc:93.33
starting validation....
training - epoch:7, avg_loss:0.36, avg_acc:86.96
val - epoch:7, avg_loss:0.34, avg_acc:89.08
batch 0 done - batch_loss: 0.27, batch_acc:90.00
batch 50 done - batch_loss: 0.47, batch_acc:83.33
batch 100 done - batch_loss: 0.27, batch_acc:90.00
batch 150 done - batch_loss: 0.36, batch_acc:86.67
batch 200 done - batch_loss: 0.46, batch_acc:83.33
batch 250 done - batch_loss: 0.16, batch_acc:96.67
batch 300 done - batch_loss: 0.36, batch_acc:76.67
batch 350 done - batch_loss: 0.25, batch_acc:96.67
batch 400 done - batch_loss: 0.23, batch_acc:90.00
batch 450 done - batch_loss: 0.18, batch_acc:100.00
batch 500 done - batch_loss: 0.30, batch_acc:86.67
batch 550 done - batch_loss: 0.71, batch_acc:70.00
batch 600 done - batch_loss: 0.80, batch_acc:76.67
batch 650 done - batch_loss: 0.76, batch_acc:80.00
batch 700 done - batch_loss: 0.53, batch_acc:86.67
batch 750 done - batch_loss: 0.43, batch_acc:76.67
batch 800 done - batch_loss: 0.71, batch_acc:70.00
batch 850 done - batch_loss: 0.72, batch_acc:63.33
batch 900 done - batch_loss: 0.50, batch_acc:73.33
batch 950 done - batch_loss: 0.52, batch_acc:73.33
batch 1000 done - batch_loss: 0.27, batch_acc:96.67
batch 1050 done - batch_loss: 0.99, batch_acc:76.67
batch 1100 done - batch_loss: 0.24, batch_acc:93.33
batch 1150 done - batch_loss: 0.52, batch_acc:80.00
batch 1200 done - batch_loss: 0.19, batch_acc:96.67
batch 1250 done - batch_loss: 0.32, batch_acc:90.00
batch 1300 done - batch_loss: 0.17, batch_acc:93.33
batch 1350 done - batch_loss: 0.29, batch_acc:86.67
batch 1400 done - batch_loss: 0.54, batch_acc:83.33
batch 1450 done - batch_loss: 0.15, batch_acc:93.33
batch 1500 done - batch_loss: 0.29, batch_acc:80.00
batch 1550 done - batch_loss: 0.12, batch_acc:96.67
batch 1600 done - batch_loss: 0.26, batch_acc:90.00
batch 1650 done - batch_loss: 0.09, batch_acc:100.00
batch 1700 done - batch_loss: 0.68, batch_acc:80.00
batch 1750 done - batch_loss: 0.14, batch_acc:93.33
batch 1800 done - batch_loss: 0.09, batch_acc:96.67
batch 1850 done - batch_loss: 0.09, batch_acc:100.00
batch 1900 done - batch_loss: 0.17, batch_acc:90.00
batch 1950 done - batch_loss: 0.13, batch_acc:96.67
batch 2000 done - batch_loss: 0.14, batch_acc:93.33
batch 2050 done - batch_loss: 0.06, batch_acc:100.00
batch 2100 done - batch_loss: 0.15, batch_acc:96.67
batch 2150 done - batch_loss: 0.10, batch_acc:96.67
batch 2200 done - batch_loss: 0.18, batch_acc:96.67
batch 2250 done - batch_loss: 0.13, batch_acc:93.33
batch 2300 done - batch_loss: 0.02, batch_acc:100.00
batch 2350 done - batch_loss: 0.23, batch_acc:93.33
batch 2400 done - batch_loss: 0.16, batch_acc:90.00
batch 2450 done - batch_loss: 0.14, batch_acc:93.33
batch 2500 done - batch_loss: 0.19, batch_acc:90.00
batch 2550 done - batch_loss: 0.13, batch_acc:93.33
batch 2600 done - batch_loss: 0.63, batch_acc:80.00
batch 2650 done - batch_loss: 0.58, batch_acc:86.67
batch 2700 done - batch_loss: 0.20, batch_acc:93.33
batch 2750 done - batch_loss: 0.11, batch_acc:100.00
batch 2800 done - batch_loss: 0.12, batch_acc:93.33
batch 2850 done - batch_loss: 0.07, batch_acc:100.00
batch 2900 done - batch_loss: 0.08, batch_acc:100.00
starting validation....
training - epoch:8, avg_loss:0.34, avg_acc:87.71
val - epoch:8, avg_loss:0.35, avg_acc:89.09
batch 0 done - batch_loss: 0.29, batch_acc:90.00
batch 50 done - batch_loss: 0.39, batch_acc:80.00
batch 100 done - batch_loss: 0.22, batch_acc:93.33
batch 150 done - batch_loss: 0.30, batch_acc:93.33
batch 200 done - batch_loss: 0.39, batch_acc:86.67
batch 250 done - batch_loss: 0.13, batch_acc:96.67
batch 300 done - batch_loss: 0.30, batch_acc:80.00
batch 350 done - batch_loss: 0.26, batch_acc:93.33
batch 400 done - batch_loss: 0.22, batch_acc:90.00
batch 450 done - batch_loss: 0.16, batch_acc:100.00
batch 500 done - batch_loss: 0.31, batch_acc:90.00
batch 550 done - batch_loss: 0.66, batch_acc:70.00
batch 600 done - batch_loss: 0.75, batch_acc:76.67
batch 650 done - batch_loss: 0.74, batch_acc:80.00
batch 700 done - batch_loss: 0.51, batch_acc:86.67
batch 750 done - batch_loss: 0.40, batch_acc:76.67
batch 800 done - batch_loss: 0.64, batch_acc:70.00
batch 850 done - batch_loss: 0.66, batch_acc:66.67
batch 900 done - batch_loss: 0.43, batch_acc:76.67
batch 950 done - batch_loss: 0.46, batch_acc:80.00
batch 1000 done - batch_loss: 0.22, batch_acc:96.67
batch 1050 done - batch_loss: 0.92, batch_acc:76.67
batch 1100 done - batch_loss: 0.22, batch_acc:96.67
batch 1150 done - batch_loss: 0.50, batch_acc:80.00
batch 1200 done - batch_loss: 0.20, batch_acc:96.67
batch 1250 done - batch_loss: 0.31, batch_acc:90.00
batch 1300 done - batch_loss: 0.16, batch_acc:93.33
batch 1350 done - batch_loss: 0.27, batch_acc:83.33
batch 1400 done - batch_loss: 0.49, batch_acc:86.67
batch 1450 done - batch_loss: 0.17, batch_acc:93.33
batch 1500 done - batch_loss: 0.26, batch_acc:83.33
batch 1550 done - batch_loss: 0.12, batch_acc:96.67
batch 1600 done - batch_loss: 0.23, batch_acc:90.00
batch 1650 done - batch_loss: 0.08, batch_acc:100.00
batch 1700 done - batch_loss: 0.63, batch_acc:76.67
batch 1750 done - batch_loss: 0.14, batch_acc:96.67
batch 1800 done - batch_loss: 0.07, batch_acc:100.00
batch 1850 done - batch_loss: 0.09, batch_acc:96.67
batch 1900 done - batch_loss: 0.13, batch_acc:90.00
batch 1950 done - batch_loss: 0.10, batch_acc:96.67
batch 2000 done - batch_loss: 0.13, batch_acc:93.33
batch 2050 done - batch_loss: 0.05, batch_acc:100.00
batch 2100 done - batch_loss: 0.14, batch_acc:96.67
batch 2150 done - batch_loss: 0.09, batch_acc:96.67
batch 2200 done - batch_loss: 0.13, batch_acc:96.67
batch 2250 done - batch_loss: 0.12, batch_acc:90.00
batch 2300 done - batch_loss: 0.02, batch_acc:100.00
batch 2350 done - batch_loss: 0.20, batch_acc:93.33
batch 2400 done - batch_loss: 0.13, batch_acc:86.67
batch 2450 done - batch_loss: 0.13, batch_acc:93.33
batch 2500 done - batch_loss: 0.18, batch_acc:93.33
batch 2550 done - batch_loss: 0.10, batch_acc:93.33
batch 2600 done - batch_loss: 0.56, batch_acc:80.00
batch 2650 done - batch_loss: 0.57, batch_acc:86.67
batch 2700 done - batch_loss: 0.17, batch_acc:96.67
batch 2750 done - batch_loss: 0.09, batch_acc:100.00
batch 2800 done - batch_loss: 0.10, batch_acc:93.33
batch 2850 done - batch_loss: 0.06, batch_acc:100.00
batch 2900 done - batch_loss: 0.05, batch_acc:100.00
starting validation....
training - epoch:9, avg_loss:0.31, avg_acc:88.48
val - epoch:9, avg_loss:0.37, avg_acc:88.90
starting testing....
done w all_ - [0, 6, 0, 0, 0, 0, 0, 0, 0, 0]
batching done
batch 0 done - loss: 0.77, acc:83.33
batch 25 done - loss: 0.29, acc:83.33
batch 50 done - loss: 1.05, acc:76.67
batch 75 done - loss: 0.22, acc:90.00
batch 100 done - loss: 0.28, acc:90.00
batch 125 done - loss: 0.82, acc:83.33
batch 150 done - loss: 0.08, acc:100.00
batch 175 done - loss: 0.48, acc:80.00
batch 200 done - loss: 0.81, acc:73.33
batch 225 done - loss: 1.92, acc:56.67
batch 250 done - loss: 1.19, acc:70.00
test done
avg_loss:0.68, avg_acc:83.01
